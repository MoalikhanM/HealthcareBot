{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39dcdc16",
   "metadata": {},
   "source": [
    "# 1. Импортирование библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd03b276",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\orala\\Documents\\Anaconda\\envs\\gpu_tf_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd  # Импорт библиотеки pandas для работы с данными\n",
    "import torch  # Импорт библиотеки PyTorch для работы с нейронными сетями\n",
    "\n",
    "from torch.utils.data import Dataset  # Импорт класса Dataset из PyTorch для создания пользовательского датасета\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments  # Импорт необходимых классов из библиотеки transformers\n",
    "from sklearn.model_selection import train_test_split  # Импорт функции для разделения данных на тренировочный и тестовый наборы"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f11e18f",
   "metadata": {},
   "source": [
    "# 2. Загрузка набора данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb527fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'dataset/Симптомы_ответы.csv'  # Путь к файлу с данными\n",
    "data = pd.read_csv(file_path)  # Загрузка данных в DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36ec348",
   "metadata": {},
   "source": [
    "### 2.1. Объединение колонок жалоб и ключевых слов для создания контекста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85882681",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['combined'] = data['Complaints'] + \" \" + data['Keywords']  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57c4e64",
   "metadata": {},
   "source": [
    "# 3. Подготовка датасета"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8712c0d",
   "metadata": {},
   "source": [
    "### 3.1. Кодирование меток"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56716134",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = {label: idx for idx, label in enumerate(data['Answer'].unique())}  # Создание словаря для кодирования уникальных ответов в числовые метки\n",
    "data['label'] = data['Answer'].map(label_encoder)  # Применение кодирования к колонке ответов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f3a6dc",
   "metadata": {},
   "source": [
    "### 3.2. Разделение данных на тренировочный и тестовый наборы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57851e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)  # Разделение данных с использованием функции train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94cbd186",
   "metadata": {},
   "source": [
    "### 3.3. Создание пользовательского класса Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8831c45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание пользовательского класса Dataset\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, max_token_len=512):\n",
    "        self.tokenizer = tokenizer  # Инициализация токенизатора\n",
    "        self.data = data  # Инициализация данных\n",
    "        self.max_token_len = max_token_len  # Максимальная длина токенов\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)  # Возвращает количество элементов в датасете\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data.iloc[idx]  # Получение элемента по индексу\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            item['combined'],  # Текст для токенизации\n",
    "            add_special_tokens=True,  # Добавление специальных токенов (CLS, SEP)\n",
    "            max_length=self.max_token_len,  # Максимальная длина токенов\n",
    "            padding=\"max_length\",  # Дополнение до максимальной длины\n",
    "            truncation=True,  # Усечение текста до максимальной длины\n",
    "            return_attention_mask=True,  # Возвращение маски внимания\n",
    "            return_tensors='pt',  # Возвращение тензоров PyTorch\n",
    "        )\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),  # Токенизированные ID\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),  # Маска внимания\n",
    "            'labels': torch.tensor(item['label'], dtype=torch.long)  # Метки в формате тензоров\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e414169",
   "metadata": {},
   "source": [
    "### 3.4. Инициализация токенизатора и датасетов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb3412b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')  # Загрузка предобученного токенизатора BERT\n",
    "train_dataset = CustomDataset(train_data, tokenizer)  # Создание тренировочного датасета\n",
    "test_dataset = CustomDataset(test_data, tokenizer)  # Создание тестового датасета"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069a5871",
   "metadata": {},
   "source": [
    "# 4. Инициализация модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b600fa9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(label_encoder))  # Загрузка предобученной модели BERT для классификации последовательностей"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b101e173",
   "metadata": {},
   "source": [
    "# 5. Аргументы тренировки и инициализация Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b193136",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',  # Директория для сохранения результатов\n",
    "    num_train_epochs=5,  # Количество эпох\n",
    "    per_device_train_batch_size=4,  # Размер батча для тренировки\n",
    "    per_device_eval_batch_size=4,  # Размер батча для оценки\n",
    "    warmup_steps=500,  # Количество шагов для разогрева\n",
    "    weight_decay=0.01,  # Коэффициент затухания весов\n",
    "    logging_dir='./logs',  # Директория для сохранения логов\n",
    "    logging_steps=10,  # Частота логирования\n",
    "    evaluation_strategy=\"epoch\",  # Стратегия оценки на каждом эпохе\n",
    "    save_strategy=\"epoch\",  # Стратегия сохранения на каждом эпохе\n",
    "    load_best_model_at_end=True,  # Загрузка лучшей модели в конце\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,  # Модель для тренировки\n",
    "    args=training_args,  # Аргументы тренировки\n",
    "    train_dataset=train_dataset,  # Тренировочный датасет\n",
    "    eval_dataset=test_dataset  # Тестовый датасет\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2abf6881",
   "metadata": {},
   "source": [
    "# 6. Тренировка модели "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4734cf3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='15' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15/15 05:15, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>3.468400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=15, training_loss=3.4565185546875, metrics={'train_runtime': 337.8886, 'train_samples_per_second': 0.355, 'train_steps_per_second': 0.044, 'total_flos': 31581264199680.0, 'train_loss': 3.4565185546875, 'epoch': 5.0})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f7df9c",
   "metadata": {},
   "source": [
    "### 6.1. Сохранить модель и токенизатор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ab114b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_path = './trained_model'\n",
    "model.save_pretrained(model_save_path)\n",
    "tokenizer.save_pretrained(model_save_path)\n",
    "\n",
    "print(f\"Model and tokenizer saved to {model_save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb0e98e",
   "metadata": {},
   "source": [
    "# 7. Оценка модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "021bfd25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results: {'eval_loss': 3.3982083797454834, 'eval_runtime': 7.4696, 'eval_samples_per_second': 0.803, 'eval_steps_per_second': 0.134, 'epoch': 5.0}\n"
     ]
    }
   ],
   "source": [
    "results = trainer.evaluate()\n",
    "\n",
    "print(\"Evaluation results:\", results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef7ebb5",
   "metadata": {},
   "source": [
    "# 10. Загрузка модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f0611c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and tokenizer loaded successfully\n",
      "Введите вашу жалобу (или 'Стоп' для завершения): кашель\n",
      "Рекомендации: Тщательная очистка и дезинфекция раны спиртом или перекисью водорода. Использование стерильных повязок для предотвращения инфекции, к примеру бинт. Наблюдение за раной и обращение к врачу при признаках инфекции или замедленного заживления.\n",
      "Введите вашу жалобу (или 'Стоп' для завершения): боль в спине\n",
      "Рекомендации: Прекращение курения и других вредных привычек. Применение медикаментозной терапии для улучшения кровообращения. Регулярные посещения кардиолога для контроля состояния.\n",
      "Введите вашу жалобу (или 'Стоп' для завершения): зубная боль\n",
      "Рекомендации: Тщательная очистка и дезинфекция раны спиртом или перекисью водорода. Использование стерильных повязок для предотвращения инфекции, к примеру бинт. Наблюдение за раной и обращение к врачу при признаках инфекции или замедленного заживления.\n",
      "Введите вашу жалобу (или 'Стоп' для завершения): боли в животе\n",
      "Рекомендации: УЗИ или КТ для определения размера и расположения камней. Медикаменты для облегчения выхода камней, достаточное употребление жидкости. В критических случаях рассмотрение литотрипсии или хирургического вмешательства.\n",
      "Введите вашу жалобу (или 'Стоп' для завершения): камни в печени\n",
      "Рекомендации: Немедленная иммобилизация поврежденной области. Рентген для определения типа и степени перелома. Хирургическое вмешательство или консервативное лечение с использованием гипса или ортеза.\n",
      "Введите вашу жалобу (или 'Стоп' для завершения): стоп\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "\n",
    "model_save_path = './trained_model'\n",
    "loaded_model = BertForSequenceClassification.from_pretrained(model_save_path)\n",
    "loaded_tokenizer = BertTokenizer.from_pretrained(model_save_path)\n",
    "\n",
    "print(\"Model and tokenizer loaded successfully\")\n",
    "\n",
    "def process_user_input(input_text):\n",
    "    inputs = loaded_tokenizer(input_text, padding=True, truncation=True, return_tensors=\"pt\")  # Токенизация пользовательского ввода\n",
    "    return inputs\n",
    "\n",
    "def predict_condition(inputs):\n",
    "    with torch.no_grad():  # Отключение вычисления градиентов для режима оценки\n",
    "        predictions = loaded_model(**inputs)  # Получение предсказаний от модели\n",
    "    return torch.argmax(predictions.logits)  # Возвращение индекса класса с наибольшей вероятностью\n",
    "\n",
    "def index_to_condition(index):\n",
    "    condition = {idx: label for label, idx in label_encoder.items()}  # Обратное кодирование меток в текстовые ответы\n",
    "    return condition[index.item()]\n",
    "\n",
    "def get_medical_advice(input_text):\n",
    "    processed_input = process_user_input(input_text)  # Обработка пользовательского ввода\n",
    "    condition_index = predict_condition(processed_input)  # Получение предсказания модели\n",
    "    condition = index_to_condition(condition_index)  # Преобразование индекса в текстовый ответ\n",
    "    return condition\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"Введите вашу жалобу (или 'Стоп' для завершения): \")  # Ввод пользователя\n",
    "    if user_input.lower() == \"стоп\":  # Проверка на завершение\n",
    "        break\n",
    "    advice = get_medical_advice(user_input)  # Получение медицинского совета\n",
    "    print(\"Рекомендации:\", advice)  # Печать предсказания"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7b39a1",
   "metadata": {},
   "source": [
    "# 8. Функции для предсказания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522edd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_user_input(input_text):\n",
    "    inputs = tokenizer(input_text, padding=True, truncation=True, return_tensors=\"pt\")  # Токенизация пользовательского ввода\n",
    "    return inputs\n",
    "\n",
    "def predict_condition(inputs):\n",
    "    with torch.no_grad():  # Отключение вычисления градиентов для режима оценки\n",
    "        predictions = model(**inputs)  # Получение предсказаний от модели\n",
    "    return torch.argmax(predictions.logits)  # Возвращение индекса класса с наибольшей вероятностью\n",
    "\n",
    "def index_to_condition(index):\n",
    "    # Обратное кодирование меток в текстовые ответы\n",
    "    condition = {idx: label for label, idx in label_encoder.items()}\n",
    "    return condition[index.item()]\n",
    "\n",
    "def get_medical_advice(input_text):\n",
    "    processed_input = process_user_input(input_text)  # Обработка пользовательского ввода\n",
    "    condition_index = predict_condition(processed_input)  # Получение предсказания модели\n",
    "    condition = index_to_condition(condition_index)  # Преобразование индекса в текстовый ответ\n",
    "    return condition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92f31c1",
   "metadata": {},
   "source": [
    "# 9. Непрерывный ввод пользователя до команды \"Стоп\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5d9653",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    user_input = input(\"Введите вашу жалобу (или 'Стоп' для завершения): \")  # Ввод пользователя\n",
    "    if user_input.lower() == \"стоп\":  # Проверка на завершение\n",
    "        break\n",
    "    advice = get_medical_advice(user_input)  # Получение медицинского совета\n",
    "    print(\"Возможное состояние:\", advice)  # Печать предсказания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af4c034",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "db32090d",
   "metadata": {},
   "source": [
    "# Изначальный тест кода"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a04bb99a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\orala\\Documents\\Anaconda\\envs\\gpu_tf_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1035' max='1035' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1035/1035 1:44:21, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>6.153500</td>\n",
       "      <td>6.133895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>5.916100</td>\n",
       "      <td>6.260179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>5.627500</td>\n",
       "      <td>6.080957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5.260800</td>\n",
       "      <td>6.070578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>5.000200</td>\n",
       "      <td>6.063757</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='104' max='52' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [52/52 03:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results: {'eval_loss': 6.063757419586182, 'eval_runtime': 94.5742, 'eval_samples_per_second': 2.189, 'eval_steps_per_second': 0.55, 'epoch': 5.0}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load and prepare dataset\n",
    "file_path = 'dataset/Симптомы_ответы.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "data['combined'] = data['Complaints'] + \" \" + data['Keywords']\n",
    "\n",
    "# Label encoding\n",
    "label_encoder = {label: idx for idx, label in enumerate(data['Answer'].unique())}\n",
    "data['label'] = data['Answer'].map(label_encoder)\n",
    "\n",
    "# Train-test split\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Custom Dataset class\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, max_token_len=512):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = data\n",
    "        self.max_token_len = max_token_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data.iloc[idx]\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            item['combined'],\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_token_len,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(item['label'], dtype=torch.long)\n",
    "        }\n",
    "\n",
    "# Initialize tokenizer and datasets\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "train_dataset = CustomDataset(train_data, tokenizer)\n",
    "test_dataset = CustomDataset(test_data, tokenizer)\n",
    "\n",
    "# Initialize model\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(label_encoder))\n",
    "\n",
    "# Training arguments and trainer\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=5,  # Increase the number of epochs\n",
    "    per_device_train_batch_size=4,  # Decrease batch size\n",
    "    per_device_eval_batch_size=4,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,  # Load the best model at the end\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n",
    "\n",
    "# Evaluate the model\n",
    "eval_results = trainer.evaluate()\n",
    "print(f\"Evaluation results: {eval_results}\")\n",
    "\n",
    "# Prediction functions\n",
    "def process_user_input(input_text):\n",
    "    inputs = tokenizer(input_text, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "    return inputs\n",
    "\n",
    "def predict_condition(inputs):\n",
    "    with torch.no_grad():\n",
    "        predictions = model(**inputs)\n",
    "    return torch.argmax(predictions.logits)\n",
    "\n",
    "def index_to_condition(index):\n",
    "    # Reverse the label encoding to get the answer\n",
    "    condition = {idx: label for label, idx in label_encoder.items()}\n",
    "    return condition[index.item()]\n",
    "\n",
    "def get_medical_advice(input_text):\n",
    "    processed_input = process_user_input(input_text)\n",
    "    condition_index = predict_condition(processed_input)\n",
    "    condition = index_to_condition(condition_index)\n",
    "    return condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d094035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results: {'eval_loss': 6.063757419586182, 'eval_runtime': 94.0747, 'eval_samples_per_second': 2.2, 'eval_steps_per_second': 0.553, 'epoch': 5.0}\n"
     ]
    }
   ],
   "source": [
    "results = trainer.evaluate()\n",
    "\n",
    "print(\"Evaluation results:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cef06b6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and tokenizer saved to ./trained_model\n"
     ]
    }
   ],
   "source": [
    "# Save the trained model and tokenizer\n",
    "model_save_path = './trained_model'\n",
    "model.save_pretrained(model_save_path)\n",
    "tokenizer.save_pretrained(model_save_path)\n",
    "\n",
    "print(f\"Model and tokenizer saved to {model_save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7ad10a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Введите вашу жалобу (или 'Стоп' для завершения): cough\n",
      "Рекомендации: Maintain hygiene and use antiseptics. Use of antibiotics or antiviral drugs as prescribed by a doctor. It is mandatory to consult a doctor for diagnosis and prescription of adequate treatment.\n",
      "Введите вашу жалобу (или 'Стоп' для завершения): fever\n",
      "Рекомендации: Maintain hygiene and use antiseptics. Use of antibiotics or antiviral drugs as prescribed by a doctor. It is mandatory to consult a doctor for diagnosis and prescription of adequate treatment.\n",
      "Введите вашу жалобу (или 'Стоп' для завершения): Стоп\n"
     ]
    }
   ],
   "source": [
    "# Continuous user input until \"Стоп\"\n",
    "while True:\n",
    "    user_input = input(\"Введите вашу жалобу (или 'Стоп' для завершения): \")\n",
    "    if user_input.lower() == \"стоп\":\n",
    "        break\n",
    "    advice = get_medical_advice(user_input)\n",
    "    print(\"Рекомендации:\", advice)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e289f23",
   "metadata": {},
   "source": [
    "### Translate to English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b2864e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translated dataset saved to dataset/Complaints_Answers_Translated.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd  # Импорт библиотеки pandas для работы с данными\n",
    "from deep_translator import GoogleTranslator  # Импорт класса GoogleTranslator из библиотеки deep_translator для перевода текста\n",
    "\n",
    "# Загрузка датасета\n",
    "file_path = 'dataset/Симптомы_ответы.csv'  # Путь к файлу с данными\n",
    "data = pd.read_csv(file_path)  # Загрузка данных в DataFrame\n",
    "\n",
    "# Инициализация переводчика\n",
    "translator = GoogleTranslator(source='ru', target='en')  # Инициализация переводчика с исходным языком русский и целевым английский\n",
    "\n",
    "# Функция для перевода текста\n",
    "def translate_text(text):\n",
    "    try:\n",
    "        return translator.translate(text)  # Пытаемся перевести текст\n",
    "    except Exception as e:\n",
    "        return text  # Возвращаем оригинальный текст в случае ошибки перевода\n",
    "\n",
    "# Перевод датасета на английский язык\n",
    "data_translated = data.copy()  # Создаем копию оригинального датасета\n",
    "data_translated['Complaints'] = data['Complaints'].apply(translate_text)  # Функцию перевода к колонке жалоб\n",
    "data_translated['Keywords'] = data['Keywords'].apply(translate_text)  # Функцию перевода к колонке ключевых слов\n",
    "data_translated['Answer'] = data['Answer'].apply(translate_text)  # Функцию перевода к колонке ответов\n",
    "\n",
    "# Сохранение переведенного датасета в новый CSV файл\n",
    "translated_file_path = 'dataset/Complaints_Answers_Translated.csv'  # Путь для сохранения нового файла\n",
    "data_translated.to_csv(translated_file_path, index=False)  # Сохранить переведенный датасет в CSV файл без индексов\n",
    "\n",
    "print(f'Translated dataset saved to {translated_file_path}')  # Сообщение о успешном сохранении файла"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0810d6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (tensorflow-gpu)",
   "language": "python",
   "name": "tensorflow-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
